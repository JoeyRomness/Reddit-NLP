{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning, Preprocessing, EDA, and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re \n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup  \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data and Tidying up the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_skeptics = './data/climateskeptics.csv'\n",
    "climate_change = './data/climatechange.csv'\n",
    "skeptics = pd.read_csv(climate_skeptics)\n",
    "change = pd.read_csv(climate_change)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2007 NASA: Arctic Ice Free By 2013!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>climateskeptics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Climate Hype is a Cover Up</td>\n",
       "      <td>NaN</td>\n",
       "      <td>climateskeptics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>These are the suggestions when you type in \"cl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>climateskeptics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>chernobyl miniseries is global warming propaganda</td>\n",
       "      <td>i thought it was anti-nuclear propaganda, whic...</td>\n",
       "      <td>climateskeptics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         post_title                                          post_text        subreddit\n",
       "0           0                                                NaN                                                NaN              NaN\n",
       "1           1               2007 NASA: Arctic Ice Free By 2013!!                                                NaN  climateskeptics\n",
       "2           2                         Climate Hype is a Cover Up                                                NaN  climateskeptics\n",
       "3           3  These are the suggestions when you type in \"cl...                                                NaN  climateskeptics\n",
       "4           4  chernobyl miniseries is global warming propaganda  i thought it was anti-nuclear propaganda, whic...  climateskeptics"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skeptics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Subreddit rules</td>\n",
       "      <td>Reddit's new look doesn't display the sidebar ...</td>\n",
       "      <td>climatechange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I'm afraid climate change is going to kill me!...</td>\n",
       "      <td>Feeling scared? Have you been listening to or ...</td>\n",
       "      <td>climatechange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>As Water Scarcity Increases, Desalination Plan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>climatechange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Scientists have developed an interactive map d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>climatechange</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         post_title                                          post_text      subreddit\n",
       "0           0                                                NaN                                                NaN            NaN\n",
       "1           1                                    Subreddit rules  Reddit's new look doesn't display the sidebar ...  climatechange\n",
       "2           2  I'm afraid climate change is going to kill me!...  Feeling scared? Have you been listening to or ...  climatechange\n",
       "3           3  As Water Scarcity Increases, Desalination Plan...                                                NaN  climatechange\n",
       "4           4  Scientists have developed an interactive map d...                                                NaN  climatechange"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1237, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1231, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skeptics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I need to drop the duplicate posts that I collected when gathering data, drop_duplicates should do that.\n",
    "skeptics.drop_duplicates(inplace=True)\n",
    "change.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My DFs have redundant/dirty columns and rows, let's get rid of them.\n",
    "skeptics.drop(columns = 'Unnamed: 0', index=0, inplace=True)\n",
    "change.drop(columns = 'Unnamed: 0', index=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's reset the indexes.\n",
    "skeptics.reset_index(drop=True, inplace=True)\n",
    "change.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subreddit rules</td>\n",
       "      <td>Reddit's new look doesn't display the sidebar ...</td>\n",
       "      <td>climatechange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm afraid climate change is going to kill me!...</td>\n",
       "      <td>Feeling scared? Have you been listening to or ...</td>\n",
       "      <td>climatechange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As Water Scarcity Increases, Desalination Plan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>climatechange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scientists have developed an interactive map d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>climatechange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Debunking \"climate skeptics,\" part 1. There is...</td>\n",
       "      <td>Hi guys! I'm thinking about making a series of...</td>\n",
       "      <td>climatechange</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          post_title                                          post_text      subreddit\n",
       "0                                    Subreddit rules  Reddit's new look doesn't display the sidebar ...  climatechange\n",
       "1  I'm afraid climate change is going to kill me!...  Feeling scared? Have you been listening to or ...  climatechange\n",
       "2  As Water Scarcity Increases, Desalination Plan...                                                NaN  climatechange\n",
       "3  Scientists have developed an interactive map d...                                                NaN  climatechange\n",
       "4  Debunking \"climate skeptics,\" part 1. There is...  Hi guys! I'm thinking about making a series of...  climatechange"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_title    object\n",
       "post_text     object\n",
       "subreddit     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_title    object\n",
       "post_text     object\n",
       "subreddit     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skeptics.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ****My dtypes are all objects, which was expected. Once I start feature engineering and tokenizing, I will be binarizing all of these columns and changing them into int/float dtypes.****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1236, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1230, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skeptics.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***I've got a pretty respectable amount of Reddit posts here after dropping all my duplicates.  1761 rows of data should be enough to generate a model that can at least perform with more accuracy then the baseline score.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_title      0\n",
       "post_text     659\n",
       "subreddit       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_title       0\n",
       "post_text     1013\n",
       "subreddit        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skeptics.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***I've got a large number of NaNs in my 'post_text' column. This was expected. What these NaNs represent reddit posts that had no text and instead had an image or a link to another website.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm Going to fill in my NaNs with blank text because I don't want to add any new words \n",
    "# That can potentially be counted as high weight words and potentially\n",
    "# Hurt my model scores.\n",
    "change.fillna(' ', inplace=True)\n",
    "skeptics.fillna(' ', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Reddit's new look doesn't display the sidebar ...\n",
       "1    Feeling scared? Have you been listening to or ...\n",
       "2                                                     \n",
       "3                                                     \n",
       "4    Hi guys! I'm thinking about making a series of...\n",
       "Name: post_text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets call .head on our 'post_text' columns to take a closer look at them\n",
    "change['post_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                     \n",
       "1                                                     \n",
       "2                                                     \n",
       "3    i thought it was anti-nuclear propaganda, whic...\n",
       "4                                                     \n",
       "5                                                     \n",
       "6    https://watchers.news/2019/07/04/record-low-te...\n",
       "7                                                     \n",
       "8    I am a person who believes in climate change, ...\n",
       "9    I'm not particularly interested in short artic...\n",
       "Name: post_text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skeptics['post_text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the cleaned dataframes before I merge them into one DF. \n",
    "change.to_csv(\"./data/climatechange_cleaned.csv\", index = False)\n",
    "skeptics.to_csv(\"./data/climateskeptics_cleaned.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Feature Engineering and Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new datafram, 'df', that combines our Climate Change and Climate Skeptics subreddits\n",
    "data = [change, skeptics]\n",
    "df = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because there aren't all that many columns in our DF there really aren't many features to be engineered. I \n",
    "#DO need to engineer my 'y' variable though, which is subreddits. So let's binarize that column.\n",
    "#I will be tokenizing my text and title columns which could technically count as feature engineering,\n",
    "#But that work is shown in the preprocessing notebook.\n",
    "\n",
    "df['subreddit'] = df['subreddit'].map({'climatechange': 1, 'climateskeptics': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to create a new column where I combine my post_title and post_text. This could be helpful\n",
    "# For feature vectorization. \n",
    "df['combined_text'] = df['post_title'] + \" \" + df['post_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's save and extract our cleaned and preprocessing ready DF before we start working with it.\n",
    "df.to_csv(\"./data/df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Model Creation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "- Before we do anything with modeling, let's first calculate our Baseline score, which is essentially the simplest prediction we can make. I want all of my model's to perform better than the baseline score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Baseline score is 0.5012165450121655. What this is saying is that about 50.0% of our data entries \n",
      "come from the 'climatechange' subreddit\n"
     ]
    }
   ],
   "source": [
    "baseline = df['subreddit'].value_counts(normalize = True).max()\n",
    "\n",
    "print(f\"Our Baseline score is {baseline}. What this is saying is that about {np.round(baseline * 100)}%\"\n",
    "      + \" of our data entries \\ncome from the 'climatechange' subreddit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Model Creation Part 1: The Hard Way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***It's time to start all of my preprocessing. I'm going to set up a function that will be able to take in a corpus, clean it, remove stop words, then lemmatize it.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating our lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#This function will manually clean any string that it receives as an input.\n",
    "def clean_text(string):\n",
    "        #This will remove most HTML artifacts in the text\n",
    "        cleaned_json = BeautifulSoup(string).get_text()\n",
    "        #This regular expression will remve all punctuation and numbers from our string\n",
    "        letters_only = re.sub(\"[^a-zA-Z]\", \" \", cleaned_json)\n",
    "        #This line will format the string into lower case, then split it along spaces\n",
    "        words = letters_only.lower().split()\n",
    "        # Creating a stops variable that includes all the common english stopwords along with some \n",
    "        # That are specifically for my subreddits (these words specifically occur extremely frequently in\n",
    "        # Both subreddits so they likely have a negative impact on model score.\n",
    "        stops = set(stopwords.words('english') + ['climate', 'change'])\n",
    "        # Take our words and create a variable that ONLY includes words that weren't in our stop words\n",
    "        meaningful_words = [w for w in words if not w in stops]\n",
    "        # Lemmatize the our meaningul words, hopefully allowing for more meaningful and impactful \n",
    "        lemmatized_words = [lemmatizer.lemmatize(i) for i in meaningful_words]\n",
    "        # Finally, join our lemmatized words, adding a space between each word, then return the result.\n",
    "        return (\" \".join(lemmatized_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train Test Split incoming! TAKE COVER\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['combined_text']], \n",
    "                                                    df['subreddit'], \n",
    "                                                    random_state = 42)                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and lemmatizing X_train, give me a second...\n",
      "Done!\n",
      "Cleaning and lemmatizing X_test, give me a second...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Time to apply our function and create the word matrixes for our model!\n",
    "\n",
    "clean_train_text = []\n",
    "clean_test_text = []\n",
    "\n",
    "print(\"Cleaning and lemmatizing X_train, give me a second...\")\n",
    "\n",
    "for combined_text in X_train['combined_text']:\n",
    "    clean_train_text.append(clean_text(combined_text))\n",
    "print(\"Done!\")\n",
    "\n",
    "print(\"Cleaning and lemmatizing X_test, give me a second...\")\n",
    "\n",
    "for combined_text in X_test['combined_text']:\n",
    "    clean_test_text.append(clean_text(combined_text))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating our \"tokenizer\". The parameters I'm setting will mostly allow it to pull a features list\n",
    "#Out of our already created lemmatized word lists.\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = None,\n",
    "                             max_features = 5000) \n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer = \"word\",\n",
    "                                   tokenizer = None,\n",
    "                                   preprocessor = None,\n",
    "                                   max_features = 5000)\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(clean_train_text)\n",
    "test_data_features = vectorizer.transform(clean_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1 = LogisticRegression()\n",
    "lr1.fit(train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Count Vec Logistic Regression score is 0.981611681990265\n",
      "Test Count Vec Logistic Regression score is 0.8152350081037277\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Count Vec Logistic Regression score is {lr1.score(train_data_features, y_train)}\")\n",
    "print(f\"Test Count Vec Logistic Regression score is {lr1.score(test_data_features, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ok so our initial score is better then expected, but as can be observed, our model has high variance and is scoring nowhere near as well against the test data. It is probably overfit.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's create a confusion matrix for this model.\n",
    "y_pred = lr1.predict(test_data_features)\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm_df = pd.DataFrame(cm,\n",
    "             columns=['pred /r/climatechange', 'pred /r/climateskeptics'],\n",
    "             index=['actual /r/climatechange', 'actual /r/climateskeptics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred /r/climatechange</th>\n",
       "      <th>pred /r/climateskeptics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual /r/climatechange</th>\n",
       "      <td>258</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual /r/climateskeptics</th>\n",
       "      <td>63</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           pred /r/climatechange  pred /r/climateskeptics\n",
       "actual /r/climatechange                      258                       51\n",
       "actual /r/climateskeptics                     63                      245"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tp, fn, fp, tn = cm.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model's classification metric scores are as follows:\n",
      "Accuracy: 0.8152350081037277\n",
      "Misclassification Rate: 0.1847649918962723\n",
      "Sensitivity: 0.8349514563106796\n",
      "Specificity: 0.7954545454545454\n",
      "Precision: 0.8037383177570093\n"
     ]
    }
   ],
   "source": [
    "#Now let's take a look at all of our differect classification metrics.\n",
    "print(\"Our model's classification metric scores are as follows:\")\n",
    "print(f\"Accuracy: {(tp+tn)/(tp+fn+fp+tn)}\") \n",
    "print(f\"Misclassification Rate: {(fp+fn)/(tp+fn+fp+tn)}\")\n",
    "print(f\"Sensitivity: {(tp)/(tp+fn)}\")\n",
    "print(f\"Specificity: {(tn)/(tn+fp)}\")\n",
    "print(f\"Precision: {(tp)/(tp+fp)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Model Creation Part 2: Gridsearch and Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up our Pipeline and Gridsearch Variables\n",
    "- I want to get the best model score possible and I have quite a few different modeling techniques that I could use. By creating data pipelines where I try different vectorizers and models I can use gridsearch to test out multiple hyperparameters within those models and vectorizers to test out what positively impacts score the most. Let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['combined_text'] = df['combined_text'].str.lower()\n",
    "df['post_title'] = df['post_title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting X and y variables for my models. I want to try using my 'combined_text' column for scoring\n",
    "#but I'd also like to check how 'post_title' scores with models, so let's set two different X variables\n",
    "#to test with.\n",
    "X1 = df['combined_text']\n",
    "X2 = df['post_title']\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's set up two train test splits here\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y, stratify=y, random_state=42)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up my pipelines.\n",
    "\n",
    "#Pipe1 will be using a count vectorizer to tokenize and logistic regression as its classification model.\n",
    "pipe1 = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "#Pipe2 will be using a Tf-Idf vectorizer to tokenize and logistic regression as its classification model\n",
    "pipe2 = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "#Pipe 3 will be using a count vectorizer to tokenize and Multinomial Naive Bayes as its classification model\n",
    "pipe3 = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('mn', MultinomialNB())\n",
    "])\n",
    "\n",
    "#Pipe 4 will be using a Tf-Idf vectorizer to tokenize and Multinomial Naive Bayes as its classification model\n",
    "pipe4 = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('mn', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up Vectorizer Hyperparameters. My pipeline will go through all of these and give me the \n",
    "# best score it can achieve.\n",
    "\n",
    "cvec_pipe_params = {\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'cvec__max_features': [1000, 3000, 5000, 6000],\n",
    "    'cvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'cvec__token_pattern': [\"[^a-z]\"],\n",
    "}\n",
    "\n",
    "    \n",
    "tvec_pipe_params = {\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "    'tvec__max_features': [1000, 3000, 5000, 6000],\n",
    "    'tvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'tvec__token_pattern': [\"[^a-z]\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up our Gridsearch variables with each of our pipelines\n",
    "gs1 = GridSearchCV(pipe1, param_grid=cvec_pipe_params, cv=3)\n",
    "gs2 = GridSearchCV(pipe2, param_grid=tvec_pipe_params, cv=3)\n",
    "gs3 = GridSearchCV(pipe3, param_grid=cvec_pipe_params, cv=3)\n",
    "gs4 = GridSearchCV(pipe4, param_grid=tvec_pipe_params, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and Scoring with our Gridsearch Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tvec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...True,\n",
       "        vocabulary=None)), ('mn', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'tvec__stop_words': [None, 'english'], 'tvec__max_features': [1000, 3000, 5000, 6000], 'tvec__ngram_range': [(1, 1), (1, 2), (1, 3)], 'tvec__token_pattern': ['[^a-z]']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alright time to kill my laptop. Let's fit and score these models. With all this we'll be able to see \n",
    "#What features worked best for scoring.\n",
    "gs1.fit(X1_train, y1_train)\n",
    "gs2.fit(X1_train, y1_train)\n",
    "gs3.fit(X1_train, y1_train)\n",
    "gs4.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Count Vectorizer LR train score is 0.7393185505678745.\n",
      " Count Vectorizer LR test score is 0.7244732576985413.\n",
      " Tf-Idf LR train score is 0.6814494321254733.\n",
      " Tf-Idf LR test score is 0.640194489465154.\n",
      " Count Vectorizer Multinomial NB train score is 0.6560302866414278.\n",
      " Count Vectorizer Multinomial NB test score is 0.5980551053484603.\n",
      " Tf-Idf Multinomial NB train score is 0.6473769605191996.\n",
      " Tf-Idf Multinomial NB test score is 0.6045380875202593.\n"
     ]
    }
   ],
   "source": [
    "#Let's look at our best scores:\n",
    "print(f\" Count Vectorizer LR train score is {(gs1.score(X1_train, y1_train))}.\")\n",
    "print(f\" Count Vectorizer LR test score is {(gs1.score(X1_test, y1_test))}.\")\n",
    "print(f\" Tf-Idf LR train score is {(gs2.score(X1_train, y1_train))}.\")\n",
    "print(f\" Tf-Idf LR test score is {(gs2.score(X1_test, y1_test))}.\")\n",
    "print(f\" Count Vectorizer Multinomial NB train score is {(gs3.score(X1_train, y1_train))}.\")\n",
    "print(f\" Count Vectorizer Multinomial NB test score is {(gs3.score(X1_test, y1_test))}.\")\n",
    "print(f\" Tf-Idf Multinomial NB train score is {(gs4.score(X1_train, y1_train))}.\")\n",
    "print(f\" Tf-Idf Multinomial NB test score is {(gs4.score(X1_test, y1_test))}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count Vectorizer LR model's best params are \n",
      "{'cvec__max_features': 3000, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': None, 'cvec__token_pattern': '[^a-z]'}\n",
      "\n",
      " Tf-Idf LR model's best params are \n",
      "{'tvec__max_features': 5000, 'tvec__ngram_range': (1, 3), 'tvec__stop_words': None, 'tvec__token_pattern': '[^a-z]'}\n",
      "\n",
      "Count Vectorizer Multinomial NB model's best params are \n",
      "{'cvec__max_features': 6000, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': None, 'cvec__token_pattern': '[^a-z]'}\n",
      "\n",
      " Tf-Idf Multinobial NB model's best params are \n",
      "{'tvec__max_features': 3000, 'tvec__ngram_range': (1, 3), 'tvec__stop_words': None, 'tvec__token_pattern': '[^a-z]'}\n"
     ]
    }
   ],
   "source": [
    "#And our best params...\n",
    "print(f\"\\nCount Vectorizer LR model's best params are \\n{gs1.best_params_}\")\n",
    "print(f\"\\n Tf-Idf LR model's best params are \\n{gs2.best_params_}\")\n",
    "print(f\"\\nCount Vectorizer Multinomial NB model's best params are \\n{gs3.best_params_}\")\n",
    "print(f\"\\n Tf-Idf Multinobial NB model's best params are \\n{gs4.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model                  | Vectorizer   | Set   | Score |\n",
    "|------------------------|--------------|-------|-------|\n",
    "| Model 1 LR             | Custom Count | Train | .9816 |\n",
    "| Model 1 LR             | Custom Count | Test  | .8103 |\n",
    "| Model 2 LR             | Count        | Train | .7393 |\n",
    "| Model 2 LR             | Count        | Test  | .7244 |\n",
    "| Model 3 LR             | Tf-Idf       | Train | .6814 |\n",
    "| Model 3 LR             | Tf-Idf       | Test  | .6401 |\n",
    "| Model 4 Multinomial NB | Count        | Train | .6560 |\n",
    "| Model 4 Multinomial NB | Count        | Test  | .5980 |\n",
    "| Model 5 Multinomial NB | Tf-Idf       | Train | .6473 |\n",
    "| Model 5 Multinomial NB | Tf-Idf       | Test  | .6045 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ok so these scores were actually worse then my first model. Huh. Some things to note though: the best N_gram range was always 1, 3 and the optimal max_features was different for each pipeline.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Attempt 3: Using Just the 'post_title' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1_post_title_only = gs1.fit(X2_train, y2_train)\n",
    "gs2_post_title_only = gs2.fit(X2_train, y2_train)\n",
    "gs3_post_title_only = gs3.fit(X2_train, y2_train)\n",
    "gs4_post_title_only = gs4.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Count Vectorizer LR train score is 0.7306652244456463.\n",
      " Count Vectorizer LR test score is 0.6304700162074555.\n",
      " Tf-Idf LR train score is 0.6533261222282315.\n",
      " Tf-Idf LR test score is 0.5721231766612642.\n",
      " Count Vectorizer Multinomial NB train score is 0.6619794483504597.\n",
      " Count Vectorizer Multinomial NB test score is 0.5834683954619124.\n",
      " Tf-Idf Multinomial NB train score is 0.6630611141157382.\n",
      " Tf-Idf Multinomial NB test score is 0.5883306320907618.\n"
     ]
    }
   ],
   "source": [
    "print(f\" Count Vectorizer LR train score is {(gs1_post_title_only.score(X2_train, y2_train))}.\")\n",
    "print(f\" Count Vectorizer LR test score is {(gs1_post_title_only.score(X2_test, y2_test))}.\")\n",
    "print(f\" Tf-Idf LR train score is {(gs2_post_title_only.score(X2_train, y2_train))}.\")\n",
    "print(f\" Tf-Idf LR test score is {(gs2_post_title_only.score(X2_test, y2_test))}.\")\n",
    "print(f\" Count Vectorizer Multinomial NB train score is {(gs3_post_title_only.score(X2_train, y2_train))}.\")\n",
    "print(f\" Count Vectorizer Multinomial NB test score is {(gs3_post_title_only.score(X2_test, y2_test))}.\")\n",
    "print(f\" Tf-Idf Multinomial NB train score is {(gs4_post_title_only.score(X2_train, y2_train))}.\")\n",
    "print(f\" Tf-Idf Multinomial NB test score is {(gs4_post_title_only.score(X2_test, y2_test))}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count Vectorizer LR model's best params are \n",
      "{'cvec__max_features': 3000, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': None, 'cvec__token_pattern': '[^a-z]'}\n",
      "\n",
      " Tf-Idf LR model's best params are \n",
      "{'tvec__max_features': 1000, 'tvec__ngram_range': (1, 2), 'tvec__stop_words': None, 'tvec__token_pattern': '[^a-z]'}\n",
      "\n",
      "Count Vectorizer Multinomial NB model's best params are \n",
      "{'cvec__max_features': 3000, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': None, 'cvec__token_pattern': '[^a-z]'}\n",
      "\n",
      " Tf-Idf Multinobial NB model's best params are \n",
      "{'tvec__max_features': 3000, 'tvec__ngram_range': (1, 3), 'tvec__stop_words': None, 'tvec__token_pattern': '[^a-z]'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nCount Vectorizer LR model's best params are \\n{gs1_post_title_only.best_params_}\")\n",
    "print(f\"\\n Tf-Idf LR model's best params are \\n{gs2_post_title_only.best_params_}\")\n",
    "print(f\"\\nCount Vectorizer Multinomial NB model's best params are \\n{gs3_post_title_only.best_params_}\")\n",
    "print(f\"\\n Tf-Idf Multinobial NB model's best params are \\n{gs4_post_title_only.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Looks like these are my worst scores yet. I figured they would be worse but I thought it would probably be best practice to check.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "- My best model was actually one that I didn't use Hyper-Parameters on. I think I know why this happened though: in that model I used an edited stop list where I added in some key words that were widely used in both subreddits like 'climate and 'change'. Because those words were used so much, removing them likely allowed for the model to choose more impactful features. I also used a lemmatizer for my strings in model one, which also seems to have helped the model detect scores.\n",
    "- A few more key takeaways: Hyperparameters matter. Despite my pipeline-gridsearch models being outperformed by my first model, they did have one advantage over it: They suffered from far less variance. In the future I'd like to figure out some ways to potentially add lemmatization and more customized stopwords sets as gridsearch hyperparameters. That would potentially allow for higher scoring models with low variance.\n",
    "- If I could keep working on this in the future, I'd want to collect more data. With more text I believe I could further increase the model's accuracy. It would also be immensely helpful if I had more post text to work with rather then just titles. Alternatively, if I could set up an image recognition neural network, I think that could be another interesting way to use this data in the future (a lot of posts gathered had images instead of text).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
